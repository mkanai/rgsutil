% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_gsfiles.R
\name{read_gsfiles}
\alias{read_gsfiles}
\alias{map_gsfiles}
\title{Read multiple files from Google Cloud Storage}
\usage{
read_gsfiles(
  remote_pattern,
  func = NULL,
  combine = c("none", "rows", "cols"),
  cache.dir = NULL,
  parallel = FALSE,
  .progress = TRUE,
  ...
)

map_gsfiles(remote_pattern, func, ...)
}
\arguments{
\item{remote_pattern}{Character string or vector. Google Cloud Storage paths or patterns
starting with "gs://". Accepts:
\itemize{
  \item Single pattern: \code{"gs://bucket/data/*.csv"}
  \item Vector of paths: \code{c("gs://bucket/file1.csv", "gs://bucket/file2.csv")}
  \item Brace expansion: \code{"gs://bucket/data/{jan,feb,mar}.csv"}
  \item Mixed patterns: \code{c("gs://bucket/2023/*.csv", "gs://bucket/2024/*.csv")}
}}

\item{func}{Function. Optional function to apply to each file after reading.
Receives the data frame and file path as arguments. If NULL, returns raw data frames.}

\item{combine}{Character string. How to combine results: "none" (list),
"rows" (rbind), or "cols" (cbind). Defaults to "none".}

\item{cache.dir}{Character string. Directory for caching downloaded files.
Defaults to getOption("rgsutil.cache_dir") or a temp directory.}

\item{parallel}{Logical or integer. Whether to read files in parallel using future.
If TRUE, uses all available cores. If integer, uses that many cores. Defaults to FALSE.}

\item{.progress}{Logical. Whether to show progress messages. Defaults to TRUE.}

\item{...}{Additional arguments passed to \code{\link{fread_wrapper}} for each file.}
}
\value{
Depending on the \code{combine} parameter:
  \itemize{
    \item "none": A named list of data frames (names are file paths)
    \item "rows": A single data frame with all rows combined
    \item "cols": A single data frame with all columns combined
  }
}
\description{
Downloads and reads multiple files from Google Cloud Storage matching patterns.
Optimizes performance by batch downloading files before reading.
}
\details{
This function optimizes reading multiple files by:
\enumerate{
  \item Listing all files matching the patterns using gcloud's native pattern expansion
  \item Checking which files need updating (if cached)
  \item Batch downloading all required files using gcloud's native parallel support
  \item Reading and optionally processing each file (optionally in parallel)
  \item Combining results based on the specified method
}

The \code{func} parameter allows custom processing of each file. It receives
two arguments: the data frame and the file path. This is useful for adding
metadata or filtering data.

When \code{parallel = TRUE}, the package will attempt to use the future
package for parallel reading if available. Install \code{future} and
\code{future.apply} packages to enable this feature.
}
\examples{
\dontrun{
# Read all CSV files and return a list
data_list <- read_gsfiles("gs://my-bucket/data/*.csv")

# Read specific files
specific_files <- read_gsfiles(c(
  "gs://my-bucket/data/file1.csv",
  "gs://my-bucket/data/file2.csv",
  "gs://my-bucket/data/file3.csv"
))

# Use brace expansion for months
monthly_data <- read_gsfiles(
  "gs://my-bucket/reports/2024-{01,02,03,04,05,06}.csv",
  combine = "rows"
)

# Or more concisely for named months
quarterly_data <- read_gsfiles(
  "gs://my-bucket/reports/2024-{jan,feb,mar}.csv",
  combine = "rows"
)

# Nested brace expansion for multiple years and months
historical_data <- read_gsfiles(
  "gs://my-bucket/reports/{2022,2023,2024}-{jan,feb,mar}.csv",
  combine = "rows"
)

# Mix different patterns
all_data <- read_gsfiles(c(
  "gs://my-bucket/2023/*.csv",
  "gs://my-bucket/2024/*.csv",
  "gs://my-bucket/archive/backup-*.csv"
), combine = "rows")

# Add source file information to each data frame
with_source <- read_gsfiles(
  "gs://my-bucket/logs/2024-*.txt",
  func = function(df, path) {
    df$source_file <- basename(path)
    df$date <- as.Date(gsub(".*-(\\\\d{4}-\\\\d{2}-\\\\d{2})\\\\.txt", "\\\\1", path))
    return(df)
  },
  combine = "rows"
)

# Process genomics files with filtering
variants <- read_gsfiles(
  "gs://genomics/chr*.vcf.bgz",
  func = function(df, path) {
    df \%>\%
      filter(QUAL > 30) \%>\%
      mutate(chromosome = gsub(".*chr(\\\\w+)\\\\..*", "\\\\1", basename(path)))
  },
  combine = "rows",
  sep = "\t"
)

# Use parallel processing for faster reading
# Requires: install.packages(c("future", "future.apply"))
large_dataset <- read_gsfiles(
  "gs://my-bucket/big-data/*.parquet",
  parallel = TRUE, # Use all available cores
  combine = "rows"
)

# Specify number of parallel workers
results <- read_gsfiles(
  "gs://my-bucket/data/file*.csv",
  parallel = 4, # Use 4 cores
  func = function(df, path) {
    # Complex processing that benefits from parallelization
    df \%>\%
      group_by(category) \%>\%
      summarise(mean_value = mean(value, na.rm = TRUE))
  }
)
}

}
\seealso{
\code{\link{read_gsfile}}, \code{\link{list_gsfile}}
}
